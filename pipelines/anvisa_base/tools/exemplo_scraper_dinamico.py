#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
EXEMPLO PR√ÅTICO: Uso do Scraper Din√¢mico
=========================================

Este script demonstra casos de uso reais do scraper din√¢mico.

Executar:
    python -m pipelines.anvisa_base.tools.exemplo_scraper_dinamico

Author: Luciano
Date: 2025-11-28
"""

import logging
import sys
from datetime import datetime
from pathlib import Path

# Configurar paths
BASE_DIR = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(BASE_DIR / "src"))

from dynamic_scraper import AnvisaDynamicScraper
from hybrid_source import HybridAnvisaSource

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def exemplo_1_descoberta_automatica():
    """
    Exemplo 1: Descoberta Autom√°tica de Arquivos
    =============================================
    
    Demonstra como o scraper descobre automaticamente todos os arquivos
    dispon√≠veis no site da ANVISA sem precisar de snippets HTML.
    """
    print("\n" + "="*80)
    print("EXEMPLO 1: Descoberta Autom√°tica de Arquivos")
    print("="*80)
    
    BASE_URL = "https://www.gov.br/anvisa/pt-br/assuntos/medicamentos/cmed/precos/anos-anteriores/anos-anteriores"
    CACHE_DIR = BASE_DIR.parent.parent / "data" / "cache" / "scraper"
    
    # Inicializar scraper
    scraper = AnvisaDynamicScraper(base_url=BASE_URL, cache_dir=CACHE_DIR)
    
    # Descobrir todos os arquivos PMC dispon√≠veis
    print("\nüì• Buscando arquivos PMC dispon√≠veis...")
    df_pmc = scraper.scrape_available_files(tipo_lista='PMC')
    
    print(f"\n‚úÖ Encontrados {len(df_pmc)} arquivos PMC")
    print("\n√öltimos 10 arquivos:")
    print(df_pmc.tail(10)[['ano', 'mes', 'mes_nome', 'url']].to_string(index=False))
    
    # Estat√≠sticas
    print(f"\nüìä Estat√≠sticas:")
    print(f"   - Anos cobertos: {df_pmc['ano'].min()} a {df_pmc['ano'].max()}")
    print(f"   - Total de meses: {len(df_pmc)}")
    print(f"   - √öltimo per√≠odo: {df_pmc.iloc[-1]['mes_nome']}/{df_pmc.iloc[-1]['ano']}")
    
    return df_pmc


def exemplo_2_deteccao_novos_arquivos():
    """
    Exemplo 2: Detec√ß√£o de Novos Arquivos
    ======================================
    
    Demonstra como detectar automaticamente novos arquivos desde a √∫ltima
    execu√ß√£o, √∫til para pipelines incrementais.
    """
    print("\n" + "="*80)
    print("EXEMPLO 2: Detec√ß√£o de Novos Arquivos (Incremental)")
    print("="*80)
    
    BASE_URL = "https://www.gov.br/anvisa/pt-br/assuntos/medicamentos/cmed/precos/anos-anteriores/anos-anteriores"
    CACHE_DIR = BASE_DIR.parent.parent / "data" / "cache" / "scraper"
    
    scraper = AnvisaDynamicScraper(base_url=BASE_URL, cache_dir=CACHE_DIR)
    
    # Primeira execu√ß√£o: descobre tudo e salva no cache
    print("\nüîç Primeira execu√ß√£o: construindo cache...")
    df_all = scraper.scrape_available_files(tipo_lista='PMVG')
    print(f"   ‚úÖ {len(df_all)} arquivos no cache")
    
    # Simular nova execu√ß√£o: detectar apenas novos
    print("\nüîç Segunda execu√ß√£o: detectando novos arquivos...")
    df_novos = scraper.get_new_files_since_last_run('PMVG')
    
    if df_novos.empty:
        print("   ‚ÑπÔ∏è Nenhum arquivo novo detectado (esperado se site n√£o atualizou)")
    else:
        print(f"   üÜï {len(df_novos)} novos arquivos detectados!")
        print(df_novos[['ano', 'mes', 'mes_nome']].to_string(index=False))
    
    return df_novos


def exemplo_3_identificacao_gaps():
    """
    Exemplo 3: Identifica√ß√£o de Per√≠odos Faltantes
    ===============================================
    
    Demonstra como identificar automaticamente gaps na cobertura de dados,
    √∫til para monitoramento de qualidade.
    """
    print("\n" + "="*80)
    print("EXEMPLO 3: Identifica√ß√£o de Gaps (Per√≠odos Faltantes)")
    print("="*80)
    
    BASE_URL = "https://www.gov.br/anvisa/pt-br/assuntos/medicamentos/cmed/precos/anos-anteriores/anos-anteriores"
    CACHE_DIR = BASE_DIR.parent.parent / "data" / "cache" / "scraper"
    
    scraper = AnvisaDynamicScraper(base_url=BASE_URL, cache_dir=CACHE_DIR)
    
    # Verificar gaps desde 2023
    print("\nüîç Verificando gaps desde janeiro/2023...")
    gaps = scraper.find_missing_periods('PMC', start_year=2023, start_month=1)
    
    if not gaps:
        print("   ‚úÖ Cobertura completa! Nenhum gap detectado.")
    else:
        print(f"   ‚ö†Ô∏è {len(gaps)} per√≠odos faltantes detectados:")
        for ano, mes in gaps[:10]:  # Mostrar primeiros 10
            print(f"      - {mes:02d}/{ano}")
        if len(gaps) > 10:
            print(f"      ... e mais {len(gaps) - 10} per√≠odos")
    
    return gaps


def exemplo_4_fonte_hibrida():
    """
    Exemplo 4: Fonte H√≠brida (Transi√ß√£o)
    =====================================
    
    Demonstra como usar a fonte h√≠brida que combina snippets (per√≠odos antigos)
    com scraper din√¢mico (per√≠odos novos).
    """
    print("\n" + "="*80)
    print("EXEMPLO 4: Fonte H√≠brida (Snippets + Scraper)")
    print("="*80)
    
    BASE_URL = "https://www.gov.br/anvisa/pt-br/assuntos/medicamentos/cmed/precos/anos-anteriores/anos-anteriores"
    CACHE_DIR = BASE_DIR.parent.parent / "data" / "cache" / "scraper"
    SNIPPETS_DIR = BASE_DIR / "tools" / "snippets"
    
    hybrid = HybridAnvisaSource(
        base_url=BASE_URL,
        cache_dir=CACHE_DIR,
        snippets_dir=SNIPPETS_DIR,
        cutoff_year=2025  # Snippets at√© 2024, scraper para 2025+
    )
    
    # Obter dados de 2024 (deve usar snippets)
    print("\nüìÇ Obtendo dados de 2024 (fonte: snippets)...")
    df_2024 = hybrid.get_links(
        tipo_lista='PMC',
        ano_inicio=2024,
        mes_inicio=1,
        ano_fim=2024,
        mes_fim=12
    )
    print(f"   ‚úÖ {len(df_2024)} meses encontrados")
    if not df_2024.empty:
        print(f"   üìä Fonte: {df_2024['fonte'].value_counts().to_dict()}")
    
    # Obter dados de 2025 (deve usar scraper)
    print("\nüåê Obtendo dados de 2025 (fonte: scraper din√¢mico)...")
    df_2025 = hybrid.get_links(
        tipo_lista='PMC',
        ano_inicio=2025,
        mes_inicio=1,
        ano_fim=2025,
        mes_fim=12
    )
    print(f"   ‚úÖ {len(df_2025)} meses encontrados")
    if not df_2025.empty:
        print(f"   üìä Fonte: {df_2025['fonte'].value_counts().to_dict()}")
    
    # Obter per√≠odo completo (h√≠brido)
    print("\nüîÑ Obtendo per√≠odo completo 2023-2025 (h√≠brido)...")
    df_completo = hybrid.get_links(
        tipo_lista='PMC',
        ano_inicio=2023,
        mes_inicio=1
    )
    print(f"   ‚úÖ {len(df_completo)} meses encontrados")
    if not df_completo.empty:
        print(f"   üìä Fontes: {df_completo['fonte'].value_counts().to_dict()}")
    
    return hybrid


def exemplo_5_validacao_qualidade():
    """
    Exemplo 5: Valida√ß√£o de Qualidade
    ==================================
    
    Demonstra como validar a qualidade da cobertura de dados e gerar
    relat√≥rios detalhados.
    """
    print("\n" + "="*80)
    print("EXEMPLO 5: Valida√ß√£o de Qualidade e Relat√≥rios")
    print("="*80)
    
    BASE_URL = "https://www.gov.br/anvisa/pt-br/assuntos/medicamentos/cmed/precos/anos-anteriores/anos-anteriores"
    CACHE_DIR = BASE_DIR.parent.parent / "data" / "cache" / "scraper"
    SNIPPETS_DIR = BASE_DIR / "tools" / "snippets"
    
    hybrid = HybridAnvisaSource(
        base_url=BASE_URL,
        cache_dir=CACHE_DIR,
        snippets_dir=SNIPPETS_DIR
    )
    
    # Gerar relat√≥rio para PMC
    print("\nüìã Gerando relat√≥rio de cobertura para PMC (desde 2023)...")
    relatorio_pmc = hybrid.validate_and_report_gaps('PMC', ano_inicio=2023)
    
    print(f"\nüìä RELAT√ìRIO PMC:")
    print(f"   Per√≠odo: {relatorio_pmc['periodo_inicio']} a {relatorio_pmc['periodo_fim']}")
    print(f"   Meses esperados: {relatorio_pmc['meses_esperados']}")
    print(f"   Meses encontrados: {relatorio_pmc['meses_encontrados']}")
    print(f"   Cobertura: {relatorio_pmc['cobertura_percentual']}%")
    print(f"   Fontes: {relatorio_pmc['fontes']}")
    
    if relatorio_pmc['gaps']:
        print(f"   ‚ö†Ô∏è Gaps: {len(relatorio_pmc['gaps'])} per√≠odos faltantes")
        for ano, mes in relatorio_pmc['gaps'][:5]:
            print(f"      - {mes:02d}/{ano}")
    else:
        print("   ‚úÖ Sem gaps detectados!")
    
    # Gerar relat√≥rio para PMVG
    print("\nüìã Gerando relat√≥rio de cobertura para PMVG (desde 2023)...")
    relatorio_pmvg = hybrid.validate_and_report_gaps('PMVG', ano_inicio=2023)
    
    print(f"\nüìä RELAT√ìRIO PMVG:")
    print(f"   Cobertura: {relatorio_pmvg['cobertura_percentual']}%")
    print(f"   Fontes: {relatorio_pmvg['fontes']}")
    
    return relatorio_pmc, relatorio_pmvg


def exemplo_6_exportacao_catalogo():
    """
    Exemplo 6: Exporta√ß√£o de Cat√°logo
    ==================================
    
    Demonstra como exportar um cat√°logo completo de todos os arquivos
    dispon√≠veis para an√°lise externa.
    """
    print("\n" + "="*80)
    print("EXEMPLO 6: Exporta√ß√£o de Cat√°logo Completo")
    print("="*80)
    
    BASE_URL = "https://www.gov.br/anvisa/pt-br/assuntos/medicamentos/cmed/precos/anos-anteriores/anos-anteriores"
    CACHE_DIR = BASE_DIR.parent.parent / "data" / "cache" / "scraper"
    
    scraper = AnvisaDynamicScraper(base_url=BASE_URL, cache_dir=CACHE_DIR)
    
    # Definir caminho de sa√≠da
    output_dir = BASE_DIR.parent.parent / "data" / "processed"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / f"catalogo_anvisa_{datetime.now():%Y%m%d}.csv"
    
    # Exportar cat√°logo
    print(f"\nüíæ Exportando cat√°logo para: {output_path}")
    scraper.export_links_catalog(output_path)
    
    print(f"   ‚úÖ Cat√°logo exportado com sucesso!")
    print(f"   üìÅ Arquivo: {output_path}")
    print(f"   üìè Tamanho: {output_path.stat().st_size / 1024:.1f} KB")
    
    return output_path


def main():
    """Executa todos os exemplos."""
    print("\n" + "="*80)
    print("DEMONSTRA√á√ÉO: Scraper Din√¢mico ANVISA")
    print("="*80)
    print("\nEste script demonstra os principais casos de uso do scraper din√¢mico.")
    print("Cada exemplo √© executado sequencialmente.\n")
    
    try:
        # Exemplo 1
        exemplo_1_descoberta_automatica()
        
        # Exemplo 2
        exemplo_2_deteccao_novos_arquivos()
        
        # Exemplo 3
        exemplo_3_identificacao_gaps()
        
        # Exemplo 4
        exemplo_4_fonte_hibrida()
        
        # Exemplo 5
        exemplo_5_validacao_qualidade()
        
        # Exemplo 6
        exemplo_6_exportacao_catalogo()
        
        print("\n" + "="*80)
        print("‚úÖ Todos os exemplos executados com sucesso!")
        print("="*80)
        
    except Exception as e:
        logger.error(f"‚ùå Erro durante execu√ß√£o: {e}", exc_info=True)
        return 1
    
    return 0


if __name__ == '__main__':
    sys.exit(main())
